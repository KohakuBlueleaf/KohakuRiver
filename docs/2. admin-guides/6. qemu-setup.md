# QEMU/KVM Setup Guide

This guide covers how to set up, validate, and configure QEMU/KVM virtualization on Runner nodes for VM-based VPS. VM VPS provides full hardware isolation and enables GPU passthrough via VFIO.

---

## Prerequisites

### Hardware Requirements

| Feature | Requirement | How to Check |
|---------|-------------|--------------|
| CPU Virtualization | Intel VT-x or AMD-V | `grep -cE 'vmx|svm' /proc/cpuinfo` (must be > 0) |
| IOMMU (for GPU passthrough) | Intel VT-d or AMD-Vi | BIOS/UEFI setting |
| GPU (for passthrough) | NVIDIA discrete GPU | `lspci | grep -i nvidia` |

### Software Requirements

| Software | Version | Purpose |
|----------|---------|---------|
| QEMU | 6.0+ | Virtual machine hypervisor |
| OVMF | Latest | UEFI firmware for VMs |
| qemu-img | (bundled with QEMU) | Disk image management |
| genisoimage or mkisofs | Latest | Cloud-init ISO creation |
| libguestfs-tools | Latest | Base image customization (optional) |

---

## Step 1: Verify CPU Virtualization

CPU virtualization extensions must be enabled in BIOS/UEFI.

```bash
# Check for Intel VT-x (vmx) or AMD-V (svm)
grep -cE 'vmx|svm' /proc/cpuinfo
```

If the output is `0`, enable virtualization in your BIOS/UEFI settings:
- **Intel**: Enable "Intel Virtualization Technology" (VT-x)
- **AMD**: Enable "SVM Mode" or "AMD-V"

After enabling, verify the KVM device exists:

```bash
ls -la /dev/kvm
```

Expected output:
```
crw-rw---- 1 root kvm 10, 232 ... /dev/kvm
```

If `/dev/kvm` does not exist, load the KVM module:

```bash
# Intel
sudo modprobe kvm_intel

# AMD
sudo modprobe kvm_amd

# Verify
lsmod | grep kvm
```

---

## Step 2: Install QEMU and Dependencies

### Ubuntu/Debian

```bash
sudo apt update
sudo apt install -y \
    qemu-system-x86 \
    qemu-utils \
    ovmf \
    genisoimage \
    cloud-image-utils
```

### RHEL/CentOS/Fedora

```bash
sudo dnf install -y \
    qemu-kvm \
    qemu-img \
    edk2-ovmf \
    genisoimage
```

### Verify Installation

```bash
# QEMU binary
qemu-system-x86_64 --version

# Disk image tool
qemu-img --version

# UEFI firmware
ls /usr/share/OVMF/OVMF_CODE*.fd 2>/dev/null || \
ls /usr/share/edk2/ovmf/OVMF_CODE*.fd 2>/dev/null

# ISO creation tool
genisoimage --version 2>/dev/null || mkisofs --version
```

---

## Step 3: Enable IOMMU (for GPU Passthrough)

GPU passthrough requires IOMMU. Skip this step if you do not need GPU passthrough.

### Configure Kernel Parameters

Edit GRUB configuration:

```bash
sudo nano /etc/default/grub
```

Add IOMMU parameters to `GRUB_CMDLINE_LINUX_DEFAULT`:

```bash
# Intel
GRUB_CMDLINE_LINUX_DEFAULT="quiet splash intel_iommu=on iommu=pt"

# AMD
GRUB_CMDLINE_LINUX_DEFAULT="quiet splash amd_iommu=on iommu=pt"
```

Update GRUB and reboot:

```bash
sudo update-grub
sudo reboot
```

### Verify IOMMU

After reboot, check IOMMU is active:

```bash
# Check kernel messages
dmesg | grep -i iommu | head -5

# Check IOMMU groups exist
ls /sys/kernel/iommu_groups/ | head -10
```

Expected: You should see numbered IOMMU group directories.

---

## Step 4: Set Up VFIO (for GPU Passthrough)

VFIO allows VMs to directly access PCI devices. Skip this step if you do not need GPU passthrough.

### Load VFIO Modules

```bash
# Load modules
sudo modprobe vfio
sudo modprobe vfio_pci
sudo modprobe vfio_iommu_type1

# Verify
lsmod | grep vfio
```

Make modules load on boot:

```bash
echo -e "vfio\nvfio_pci\nvfio_iommu_type1" | sudo tee /etc/modules-load.d/vfio.conf
```

### Inspect GPU IOMMU Groups

KohakuRiver automatically discovers GPUs suitable for passthrough. To manually inspect:

```bash
# List all NVIDIA GPUs
lspci -nn | grep -i nvidia

# Example output:
# 01:00.0 VGA compatible controller [0300]: NVIDIA Corporation ... [10de:2684]
# 01:00.1 Audio device [0403]: NVIDIA Corporation ... [10de:22ba]
```

Check the IOMMU group for a GPU:

```bash
# Replace 0000:01:00.0 with your GPU's PCI address
IOMMU_GROUP=$(basename $(readlink /sys/bus/pci/devices/0000:01:00.0/iommu_group))
echo "IOMMU Group: $IOMMU_GROUP"

# List all devices in the group
ls /sys/kernel/iommu_groups/$IOMMU_GROUP/devices/
```

KohakuRiver handles IOMMU groups intelligently:
- **PCI bridges** (class `0x06xx`) in the group are ignored — they are kernel-managed and do not need VFIO binding
- **Multiple GPUs** sharing a group (common on server hardware with NVLink/PCIe switches) are automatically co-allocated — requesting one GPU auto-includes its group peers
- **Audio devices** (class `0x0403`) in the same slot are automatically passed through with the GPU
- **Other endpoint devices** are flagged with warnings but still supported — all non-bridge endpoints in the group are co-bound to vfio-pci as required by the VFIO kernel

This means server GPUs behind PCIe switches (e.g., V100 SXM2, A100 SXM4) work out of the box without ACS override patches.

### Verify with KohakuRiver

KohakuRiver provides built-in capability detection:

```bash
# Run capability check with detailed output
kohakuriver qemu check
```

This displays a table with all check results, discovered GPUs, IOMMU group peers, and the host NVIDIA driver version.

The runner heartbeat also automatically reports VM capability to the host. You can verify in the host dashboard or via CLI:

```bash
kohakuriver node list
```

Nodes with VM capability will show `vm_capable: true`.

---

## Step 5: Create Base VM Image

KohakuRiver VMs boot from qcow2 base images stored in `/var/lib/kohakuriver/vm-images/`.

### Using the CLI (Recommended)

```bash
# Create default Ubuntu 24.04 base image (500G virtual, thin-provisioned)
sudo kohakuriver qemu image create

# Custom options
sudo kohakuriver qemu image create \
    --name ubuntu-24.04-gpu \
    --size 500G \
    --ubuntu-version 24.04

# With NVIDIA drivers (auto-detects host driver version)
sudo kohakuriver qemu image create \
    --name ubuntu-24.04-gpu \
    --with-nvidia

# Override NVIDIA driver version
sudo kohakuriver qemu image create \
    --name ubuntu-24.04-gpu \
    --with-nvidia --nvidia-version 550.90.07
```

The CLI command:
1. Downloads the Ubuntu cloud image (cached in `/tmp/kohakuriver-vm-cache/`)
2. Copies and resizes to the specified virtual disk size (thin-provisioned — actual host usage starts small and grows on demand)
3. Customizes with `virt-customize` (if available): installs SSH, cloud-init, qemu-guest-agent
4. Optionally installs matching NVIDIA drivers via `--with-nvidia`
5. Outputs to `/var/lib/kohakuriver/vm-images/<name>.qcow2`

> **Note on thin provisioning:** The disk size parameter sets the *maximum virtual size* visible to the guest. The actual host file starts small (~500 MB) and grows only as the guest writes data. Setting a large value (e.g., 500G) is safe and recommended.

### List Available Images

```bash
kohakuriver qemu image list
```

### Validate Setup

```bash
kohakuriver qemu check
```

This shows a capability check table and lists all discovered VFIO GPUs with IOMMU group peer information.

### Using the Shell Script (Deprecated)

The shell script `scripts/create-vm-base-image.sh` is still available but deprecated in favor of the CLI command above.

```bash
sudo ./scripts/create-vm-base-image.sh --name ubuntu-24.04 --size 500G
```

### Manual Base Image Creation

If you prefer to create a base image manually or use a different distribution:

```bash
# Create the images directory
sudo mkdir -p /var/lib/kohakuriver/vm-images

# Download a cloud image
wget -O /tmp/ubuntu-cloud.img \
    https://cloud-images.ubuntu.com/releases/24.04/release/ubuntu-24.04-server-cloudimg-amd64.img

# Copy and resize
sudo cp /tmp/ubuntu-cloud.img /var/lib/kohakuriver/vm-images/ubuntu-24.04.qcow2
sudo qemu-img resize /var/lib/kohakuriver/vm-images/ubuntu-24.04.qcow2 50G
```

### Requirements for Base Images

Base images used by KohakuRiver must have:

| Requirement | Why |
|-------------|-----|
| cloud-init | VM provisioning (users, SSH keys, networking) |
| OpenSSH server | SSH access to VMs |
| Python 3 | VM agent runs as Python script |
| qemu-guest-agent | Graceful shutdown support |

### Adding NVIDIA Drivers (for GPU Passthrough)

For VMs that will use GPU passthrough, the base image needs NVIDIA drivers. The easiest way is to use the CLI with `--with-nvidia`:

```bash
sudo kohakuriver qemu image create --name ubuntu-24.04-gpu --with-nvidia
```

This auto-detects the host NVIDIA driver version and installs the matching version in the image with DKMS support.

To install manually:

```bash
sudo virt-customize -a /var/lib/kohakuriver/vm-images/ubuntu-24.04.qcow2 \
    --install 'build-essential,dkms,linux-headers-generic,pkg-config,libglvnd-dev' \
    --upload /path/to/NVIDIA-Linux-x86_64-550.90.07.run:/tmp/nvidia.run \
    --run-command 'chmod +x /tmp/nvidia.run && /tmp/nvidia.run --silent --dkms --no-cc-version-check' \
    --run-command 'rm /tmp/nvidia.run'
```

> **Note:** VMs with VFIO GPU passthrough run their own complete driver stack. The driver is installed with `--dkms` for automatic kernel module rebuild. The `--no-cc-version-check` flag avoids gcc version mismatch issues between the image build environment and runtime. The driver version should match the host driver for best compatibility.

---

## Step 6: Configure the Runner

Add VM-related settings to `~/.kohakuriver/runner_config.py`:

```python
# =============================================================================
# VM (QEMU/KVM) Configuration
# =============================================================================

# Directory for base VM images (qcow2)
VM_IMAGES_DIR: str = "/var/lib/kohakuriver/vm-images"

# Directory for VM instance data (overlay disks, cloud-init ISOs, QMP sockets)
VM_INSTANCES_DIR: str = "/var/lib/kohakuriver/vm-instances"

# Default VM settings (can be overridden per-VM at creation time)
VM_DEFAULT_MEMORY_MB: int = 4096        # 4 GB
VM_DEFAULT_DISK_SIZE: str = "500G"   # Virtual max, thin-provisioned

# Timeouts
VM_BOOT_TIMEOUT_SECONDS: int = 120      # Max wait for VM to boot
VM_SSH_READY_TIMEOUT_SECONDS: int = 120  # Max wait for SSH to become available
VM_HEARTBEAT_TIMEOUT_SECONDS: int = 60   # Mark VM unhealthy after no heartbeat

# NAT bridge settings (used when overlay is disabled)
VM_BRIDGE_NAME: str = "kohaku-br0"
VM_BRIDGE_SUBNET: str = "10.200.0.0/24"
VM_BRIDGE_GATEWAY: str = "10.200.0.1"
```

Ensure the directories exist:

```bash
sudo mkdir -p /var/lib/kohakuriver/vm-images
sudo mkdir -p /var/lib/kohakuriver/vm-instances
```

---

## Step 7: Validate the Setup

### Automated Validation

Start the runner and check the startup logs:

```bash
kohakuriver runner
```

Look for these messages in the logs:

```
VM capability: vm_capable=True
  KVM: OK
  QEMU: OK (/usr/bin/qemu-system-x86_64)
  OVMF: OK (/usr/share/OVMF/OVMF_CODE_4M.fd)
  ISO tool: OK (genisoimage)
  IOMMU: OK (N groups)
  VFIO: OK (modules loaded)
  VFIO GPUs: N discovered
```

### Manual Validation Checklist

Run these checks on each runner node:

```bash
echo "=== KVM ==="
test -c /dev/kvm && echo "OK: /dev/kvm exists" || echo "FAIL: /dev/kvm missing"

echo ""
echo "=== CPU Virtualization ==="
grep -cE 'vmx|svm' /proc/cpuinfo | \
    xargs -I{} bash -c '[ {} -gt 0 ] && echo "OK: {} cores with VT-x/AMD-V" || echo "FAIL: No virtualization"'

echo ""
echo "=== QEMU ==="
command -v qemu-system-x86_64 && echo "OK" || echo "FAIL: qemu-system-x86_64 not found"

echo ""
echo "=== OVMF Firmware ==="
ls /usr/share/OVMF/OVMF_CODE*.fd 2>/dev/null && echo "OK" || \
ls /usr/share/edk2/ovmf/OVMF_CODE*.fd 2>/dev/null && echo "OK" || echo "FAIL: OVMF not found"

echo ""
echo "=== ISO Tool ==="
command -v genisoimage 2>/dev/null && echo "OK: genisoimage" || \
command -v mkisofs 2>/dev/null && echo "OK: mkisofs" || echo "FAIL: No ISO tool"

echo ""
echo "=== IOMMU ==="
ls /sys/kernel/iommu_groups/ 2>/dev/null | wc -l | \
    xargs -I{} bash -c '[ {} -gt 0 ] && echo "OK: {} groups" || echo "WARN: No IOMMU groups (GPU passthrough unavailable)"'

echo ""
echo "=== VFIO Modules ==="
lsmod | grep -q vfio_pci && echo "OK: vfio_pci loaded" || echo "WARN: vfio_pci not loaded (GPU passthrough unavailable)"

echo ""
echo "=== Base Images ==="
ls /var/lib/kohakuriver/vm-images/*.qcow2 2>/dev/null && echo "OK" || echo "WARN: No base images found"
```

### Test VM Creation

Create a test VM via CLI:

```bash
kohakuriver vps create \
    --backend qemu \
    --vm-image ubuntu-24.04 \
    --vm-memory 2048 \
    --cores 2 \
    --ssh
```

Monitor the creation:

```bash
kohakuriver vps status <task_id>
```

The VM should progress through: `pending → running` with SSH becoming available.

---

## Troubleshooting

### "KVM not available" or "/dev/kvm missing"

1. Verify CPU virtualization is enabled in BIOS
2. Load the KVM module: `sudo modprobe kvm_intel` (or `kvm_amd`)
3. Check if another hypervisor is using KVM (e.g., VirtualBox)

### "OVMF firmware not found"

Install the OVMF package:

```bash
# Ubuntu/Debian
sudo apt install ovmf

# RHEL/CentOS
sudo dnf install edk2-ovmf
```

### "IOMMU not enabled"

1. Verify kernel parameters include `intel_iommu=on` (or `amd_iommu=on`):
   ```bash
   cat /proc/cmdline | grep iommu
   ```
2. If missing, update GRUB (see Step 3) and reboot

### "VFIO modules not loaded"

```bash
sudo modprobe vfio vfio_pci vfio_iommu_type1
```

If modules fail to load, check if they are available:

```bash
find /lib/modules/$(uname -r) -name 'vfio*'
```

### "No suitable VFIO GPUs"

Common causes:
- GPU is currently in use by the display server (X11/Wayland)
- GPU is bound to a driver that can't be unbound
- No NVIDIA GPUs detected on the system

> **Note:** IOMMU groups with PCIe bridges/switches (common on server hardware) are now handled automatically. GPUs sharing a group with bridges will be discovered correctly.

Check the GPU's current driver:

```bash
lspci -k -s 01:00.0
# Look for "Kernel driver in use:"
```

Run `kohakuriver qemu check` for detailed IOMMU group analysis.

### VM fails to get network

- **Overlay mode**: Ensure the overlay network is configured and `kohaku-overlay` bridge exists
- **Standard mode**: Check if `kohaku-br0` bridge was created (runner creates it automatically)
- Verify iptables MASQUERADE rule: `sudo iptables -t nat -L POSTROUTING -n`

---

## Security Considerations

- QEMU processes run as root on the runner (required for KVM and VFIO access)
- VFIO GPU binding temporarily removes the GPU from the host; other processes lose access
- VM disk images contain user data; ensure `/var/lib/kohakuriver/vm-instances/` has appropriate permissions
- The cloud-init ISO contains SSH keys; it is stored temporarily and can be removed after VM boot
- VMs on NAT bridge (`kohaku-br0`) can access the runner's network; firewall rules should restrict access to sensitive services
